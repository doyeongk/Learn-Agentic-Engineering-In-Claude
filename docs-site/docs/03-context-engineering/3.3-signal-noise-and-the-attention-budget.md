---
sidebar_position: 3
sidebar_label: "Signal, Noise, and Attention"
title: "Understanding Signal, Noise, and the Attention Budget"
diataxis_type: explanation
estimated_time: 20
module_id: "3.3"
description: "Why more information is not always better, how context rot happens, and the mental model of an attention budget."
---

# Understanding Signal, Noise, and the Attention Budget

> **Key question**: If the context window is so large, why can't you just put everything in it?

## Context

You now know that context is the information an AI model sees when generating a response. You know that CLAUDE.md is a powerful way to provide that context. The natural instinct is to make CLAUDE.md as comprehensive as possible — document every convention, every file, every edge case.

This instinct is wrong. And understanding why is the key to effective context engineering.

## The Core Idea

Think of a radio signal. When the signal is strong and the background noise is low, you hear the music clearly. When you crank up the noise — static, interference, other stations — the music is still there, but you cannot make it out. The signal has not changed. The noise has drowned it out.

AI models work the same way. The context window is like the radio receiver. Your important instructions (the signal) compete with everything else in the window (the noise). The more irrelevant information you add, the harder it becomes for the model to focus on what matters.

This gives us a mental model: the **attention budget**. Every piece of information in the context window consumes some of the model's attention. Attention is finite. Spend it on noise, and there is less left for signal.

### The Attention Budget

Imagine you have 100 units of attention:

| Scenario | Signal | Noise | Attention on Signal |
|----------|--------|-------|-------------------|
| Lean CLAUDE.md (500 words) | 500 words | 0 | ~100% |
| Padded CLAUDE.md (2000 words) | 500 words | 1500 words | ~25% |
| Kitchen-sink CLAUDE.md (5000 words) | 500 words | 4500 words | ~10% |

The useful instructions are the same in all three cases. But the model's ability to follow them degrades as irrelevant content grows. This is not a metaphor — research on large language models shows that performance on tasks measurably decreases when relevant information is buried in irrelevant context.

## How It Works

### Context Rot

Over the course of a long Claude Code session, the context window fills up. Early messages, tool results, file contents — they all accumulate. The conversation gets longer, and the model's ability to recall and prioritise early instructions diminishes.

This phenomenon is called **context rot**. The signal that was clear at the start of the session becomes harder to hear as more information piles on top. The instructions in CLAUDE.md are still there, but they are competing with thousands of lines of tool output, file contents, and conversation history.

### The Serial Position Effect

AI models (like humans) tend to pay more attention to information at the beginning and end of the context window, and less to what is in the middle. This is called the serial position effect. It means:

- Instructions at the top of CLAUDE.md get strong attention
- Instructions buried in the middle of a long file get weaker attention
- The most recent messages in a conversation get strong attention

This is why CLAUDE.md should lead with the most important information. It is also why long sessions become less reliable — the most recent context (conversation tail) starts competing with the foundational context (CLAUDE.md).

### Anthropic's Guidance

Anthropic's own recommendations for working with Claude emphasise this: provide the **smallest effective set** of context. Do not include information "just in case." Every piece of context should earn its place by directly improving the model's ability to complete the task.

This matches Karpathy's framing: the skill is not just choosing *what* to include, but choosing what to *exclude*. The best context engineers are aggressive editors.

## Trade-offs and Alternatives

There is a tension between two valid goals:

1. **Completeness** — the model should have everything it might need
2. **Focus** — the model should not be distracted by what it does not need

The resolution is layered context. Instead of putting everything in CLAUDE.md, you put only the essentials there. Specialised information goes in skill files, which are loaded only when relevant. This is exactly how this project works:

- **CLAUDE.md** contains the architecture, conventions, and progress tracking rules (always loaded)
- **Skill files** contain teaching procedures, diataxis guidelines, and design conventions (loaded only when a command needs them)

This layered approach keeps the base context lean while making detailed information available on demand.

## Common Misconceptions

**"Put everything in CLAUDE.md just in case."**
This is the most common mistake. A massive CLAUDE.md dilutes the instructions the model actually needs. If you find yourself writing a CLAUDE.md longer than ~1000 words, consider what can move to a skill file or separate document loaded on demand.

**"Longer prompts give better results."**
For simple tasks, a longer prompt with more examples can help. For complex tasks that already fill the context window with file contents and tool results, a longer prompt just adds noise. The relationship between prompt length and quality is not linear — it has a peak, and then it declines.

**"The model will ignore what it doesn't need."**
It will not. The model processes everything in the context window. Irrelevant content does not just sit passively — it actively competes for attention. This is why "just in case" content is actively harmful, not just wasteful.

## Connections

This module explains the *why* behind many design decisions in this project. CLAUDE.md is deliberately concise. Skills are loaded on demand. Command launchers specify exactly which files to read. Progress is tracked in structured JSON, not verbose prose.

In Module 3.4, you will learn practical techniques for managing context during long sessions — including when to start fresh and how to use `/compact`. In Module 3.5, the hierarchy reference shows how Claude Code's layered context system works in practice.

## Knowledge Check

1. What is "context rot"?
   - A) When files in the project become outdated
   - B) When CLAUDE.md is deleted
   - C) When the growing context window dilutes the model's ability to follow early instructions
   - D) When the model runs out of memory

2. In your own words, explain the radio signal analogy. Why is removing noise sometimes more effective than amplifying the signal?

## Further Reading

- [Managing Long Sessions](./3.4-managing-long-sessions.md) — practical techniques for keeping context clean
- [The CLAUDE.md Hierarchy](./3.5-the-claudemd-hierarchy.md) — how layered context avoids the "kitchen sink" problem
